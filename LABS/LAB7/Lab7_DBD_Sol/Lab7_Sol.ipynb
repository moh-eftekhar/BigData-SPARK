{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Task 1\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and output folders\n",
    "#inputPath  = \"sampleData/registerSample.csv\" # args[0]\n",
    "#inputPath2 = \"sampleData/stations.csv\" # args[1]\n",
    "#threshold  = 0.4 # args[2]\n",
    "inputPath  = \"/data/students/bigdata-01QYD/Lab7_DBD/register.csv\" # args[0]\n",
    "inputPath2 = \"/data/students/bigdata-01QYD/Lab7_DBD/stations.csv\" # args[1]\n",
    "threshold  = 0.6 # args[2]\n",
    "outputPath = \"out_Lab7\" # args[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the input file register.csv\n",
    "inputRDD = sc.textFile(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that is used to remove the header and the lines with #free slots=0 && #used slots=0\n",
    "def cleanData(line):\n",
    "    # Remove header\n",
    "    if line.startswith('s'):\n",
    "        return False\n",
    "    else:\n",
    "        fields = line.split(\"\\t\")\n",
    "        usedSlots = int(fields[2])\n",
    "        freeSlots = int(fields[3])\n",
    "        # Select the lines with freeSlots!=0 || usedSlots!=0\n",
    "        if freeSlots != 0 or usedSlots != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the header and the lines with #free slots=0 && #used slots=0\n",
    "filteredRDD = inputRDD.filter(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that is used to map each input line to a pair\n",
    "# key = (StationId,Weekday,Hour)\n",
    "# value = (1,1) if the station is full, (1,0) if the station is not full\n",
    "def checkFull(line):\n",
    "    # station\\ttimestamp\\tused\\tfree\n",
    "    # 1\\t2008-05-15 12:01:00\\t0\\t18\n",
    "    fields = line.split(\"\\t\")\n",
    "    stationId = fields[0]\n",
    "    freeSlots = int(fields[3])\n",
    "    timestamp = fields[1]\n",
    "    \n",
    "    datetimeObject = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")    \n",
    "    dayOfTheWeek = datetimeObject.strftime(\"%A\")\n",
    "    hour = datetimeObject.hour\n",
    "\n",
    "    if freeSlots == 0:\n",
    "        # The station is full\n",
    "        countTotReadingsTotFull = (1, 1)\n",
    "    else:\n",
    "        countTotReadingsTotFull = (1, 0)\n",
    "        \n",
    "    return ((stationId, dayOfTheWeek, hour), countTotReadingsTotFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each line to a pair\n",
    "# key = StationId_DayOfTheWeek_Hour\n",
    "# value = (1,1) if the station is full, (1,0) if the station is not full\n",
    "stationWeekDayHour = filteredRDD.map(checkFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of readings and \"full\" readings for each key\n",
    "stationWeekDayHourCounts = stationWeekDayHour.reduceByKey(lambda p1, p2: (p1[0]+p2[0], p1[1]+p2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute criticality for each key\n",
    "stationWeekDayHourCriticality = stationWeekDayHourCounts.mapValues(lambda value: value[1]/value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the pairs with criticality > threshold\n",
    "selectedPairs = stationWeekDayHourCriticality.filter(lambda pair: pair[1]>= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next part of the code selects for each station the timeslot\n",
    "# (dayOfTheWeek, Hour) with the maximum cardinality. \n",
    "# If there is more than one timeslot with the same criticality\n",
    "# for the same station, only one of them is selected (see the problem specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new PairRDD with\n",
    "# key = station Id\n",
    "# value = DayOfTheWeek, Hour, Criticality\n",
    "stationTimeslotCrit = selectedPairs.map(lambda StationWeekdayHourCrit:\\\n",
    "                                        (StationWeekdayHourCrit[0][0],\\\n",
    "                                         (StationWeekdayHourCrit[0][1], StationWeekdayHourCrit[0][2], StationWeekdayHourCrit[1])\\\n",
    "                                        ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare criticality between two timeslots\n",
    "def compareCriticality(timeslotCrit1, timeslotCrit2):\n",
    "\n",
    "    weekday1 = timeslotCrit1[0]\n",
    "    weekday2 = timeslotCrit2[0]\n",
    "    \n",
    "    hour1 = timeslotCrit1[1]\n",
    "    hour2 = timeslotCrit2[1]\n",
    "\n",
    "    crit1 = timeslotCrit1[2]\n",
    "    crit2 = timeslotCrit2[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if crit1>crit2 or \\\n",
    "    (crit1==crit2 and hour1<hour2) or \\\n",
    "    (crit1==crit2 and hour1==hour2 and weekday1<weekday2):\n",
    "        return timeslotCrit1\n",
    "    else:\n",
    "        return timeslotCrit2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the timeslot (dayOfTheWeek, Hour) with the maximum criticality for each station\n",
    "resultRDD = stationTimeslotCrit.reduceByKey(compareCriticality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return\n",
    "# - key = stationId\n",
    "# - value = (long, lat) \n",
    "def extractStationLongLat(line):\n",
    "    fields = line.split(\"\\t\")\n",
    "    \n",
    "    return (fields[0], (fields[1] ,fields[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the location of the stations\n",
    "stationLocation = sc.textFile(inputPath2).map(extractStationLongLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the locations with the \"critical\" stations\n",
    "resultLocations = resultRDD.join(stationLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a string that represents a KML marker\n",
    "def formatKMLMarker(pair):\n",
    "    # input\n",
    "    # (stationId, ( (weekday, hour, criticality), (long, lat) ) )\n",
    "    stationId = pair[0]\n",
    "    \n",
    "    weekday = pair[1][0][0]\n",
    "    hour = pair[1][0][1]\n",
    "    criticality = pair[1][0][2]\n",
    "    coordinates = pair[1][1][0]+\",\"+pair[1][1][1]\n",
    "    \n",
    "    result = \"<Placemark><name>\" + stationId + \"</name>\" + \"<ExtendedData>\"\\\n",
    "    + \"<Data name=\\\"DayWeek\\\"><value>\" + weekday + \"</value></Data>\"\\\n",
    "    + \"<Data name=\\\"Hour\\\"><value>\" + str(hour) + \"</value></Data>\"\\\n",
    "    + \"<Data name=\\\"Criticality\\\"><value>\" + str(criticality) + \"</value></Data>\"\\\n",
    "    + \"</ExtendedData>\" + \"<Point>\" + \"<coordinates>\" + coordinates + \"</coordinates>\"\\\n",
    "    + \"</Point>\" + \"</Placemark>\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string containing the description of a marker, in the KML format, for each\n",
    "# sensor and the associated information\n",
    "resultKML = resultLocations.map(formatKMLMarker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultKML.coalesce(1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the number of partitions to 1 for resultKML and store it in the output folder\n",
    "resultKML.coalesce(1).saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
